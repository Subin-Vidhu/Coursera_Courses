{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Machine Learning Foundation\n\n## Section 2, Part c: Cross Validation\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Learning objectives\n\nBy the end of this lesson, you will be able to:\n\n*   Chain multiple data processing steps together using `Pipeline`\n*   Use the `KFolds` object to split data into multiple folds.\n*   Perform cross validation using SciKit Learn with `cross_val_predict` and `GridSearchCV`\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import piplite\nawait piplite.install(['tqdm', 'seaborn', 'skillsnetwork', 'pandas', 'numpy', 'scikit-learn'])",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Surpress warnings:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\n\nimport numpy as np\nimport pickle\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skillsnetwork\n\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.model_selection import KFold, cross_val_predict\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.metrics import r2_score\nfrom sklearn.pipeline import Pipeline",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:20:55.865735Z",
          "start_time": "2019-02-19T17:20:54.685698Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Note we are loading a slightly different (\"cleaned\") pickle file\n\nURL = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML240EN-SkillsNetwork/labs/data/boston_housing_clean.pickle'\nawait skillsnetwork.download_dataset(URL)\n\nboston = pickle.load(open('boston_housing_clean.pickle', \"rb\" ))\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stderr",
          "text": "boston_housing_clean.pickle: 100%|##########| 60056/60056 [00:00<00:00, 127507.51it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Saved as boston_housing_clean.pickle\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "boston.keys()",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:21:01.676948Z",
          "start_time": "2019-02-19T17:21:01.671315Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "dict_keys(['dataframe', 'description'])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "boston_data = boston['dataframe']\nboston_description = boston['description']",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:21:10.682135Z",
          "start_time": "2019-02-19T17:21:10.678835Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "boston_data.head()",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:22:10.274974Z",
          "start_time": "2019-02-19T17:22:10.256879Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n\n   PTRATIO       B  LSTAT  MEDV  \n0     15.3  396.90   4.98  24.0  \n1     17.8  396.90   9.14  21.6  \n2     17.8  392.83   4.03  34.7  \n3     18.7  394.63   2.94  33.4  \n4     18.7  396.90   5.33  36.2  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1.0</td>\n      <td>296.0</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n      <td>34.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n      <td>33.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n      <td>36.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Discussion:\n\nSuppose we want to do Linear Regression on our dataset to get an estimate, based on mean squared error, of how well our model will perform on data outside our dataset.\n\nSuppose also that our data is split into three folds: Fold 1, Fold 2, and Fold 3.\n\nWhat would the steps be, in English, to do this?\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Your response below**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Coding this up\n\nThe [`KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) object in SciKit Learn tells the cross validation object (see below) how to split up the data:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = boston_data.drop('MEDV', axis=1)\ny = boston_data.MEDV",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:23:05.068445Z",
          "start_time": "2019-02-19T17:23:05.064683Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "kf = KFold(shuffle=True, random_state=72018, n_splits=3)",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:23:10.538982Z",
          "start_time": "2019-02-19T17:23:10.534325Z"
        },
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "for train_index, test_index in kf.split(X):\n    print(\"Train index:\", train_index[:10], len(train_index))\n    print(\"Test index:\",test_index[:10], len(test_index))\n    print('')",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:25:04.578536Z",
          "start_time": "2019-02-19T17:25:04.568959Z"
        },
        "scrolled": true,
        "trusted": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train index: [ 1  3  4  5  7  8 10 11 12 13] 337\nTest index: [ 0  2  6  9 15 17 19 23 25 26] 169\n\nTrain index: [ 0  2  6  9 10 11 12 13 15 17] 337\nTest index: [ 1  3  4  5  7  8 14 16 22 27] 169\n\nTrain index: [0 1 2 3 4 5 6 7 8 9] 338\nTest index: [10 11 12 13 18 20 21 24 28 31] 168\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "#from sklearn.metrics import r2_score, mean_squared_error\n\nscores = []\nlr = LinearRegression()\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test, y_train, y_test = (X.iloc[train_index, :], \n                                        X.iloc[test_index, :], \n                                        y[train_index], \n                                        y[test_index])\n    \n    lr.fit(X_train, y_train)\n        \n    y_pred = lr.predict(X_test)\n\n    score = r2_score(y_test.values, y_pred)\n    \n    scores.append(score)\n    \nscores",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:28:10.441616Z",
          "start_time": "2019-02-19T17:28:10.204857Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[0.6719348798472728, 0.7485020059212355, 0.6976807323597805]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "A bit cumbersome, but do-able.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Discussion (Part 2):\n\nNow suppose we want to do the same, but appropriately scaling our data as we go through the folds.\n\nWhat would the steps be *now*?\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Your response below**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Coding this up\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scores = []\n\nlr = LinearRegression()\ns = StandardScaler()\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test, y_train, y_test = (X.iloc[train_index, :], \n                                        X.iloc[test_index, :], \n                                        y[train_index], \n                                        y[test_index])\n    \n    X_train_s = s.fit_transform(X_train)\n    \n    lr.fit(X_train_s, y_train)\n    \n    X_test_s = s.transform(X_test)\n    \n    y_pred = lr.predict(X_test_s)\n\n    score = r2_score(y_test.values, y_pred)\n    \n    scores.append(score)",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:32:07.846336Z",
          "start_time": "2019-02-19T17:32:07.808810Z"
        },
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "scores",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:32:09.978972Z",
          "start_time": "2019-02-19T17:32:09.974341Z"
        },
        "trusted": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[0.6719348798472711, 0.748502005921238, 0.6976807323597745]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "(same scores, because for vanilla linear regression with no regularization, scaling actually doesn't matter for performance)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This is getting quite cumbersome!\n\n*Very* luckily, SciKit Learn has some wonderful functions that handle a lot of this for us.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### `Pipeline` and `cross_val_predict`\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "`Pipeline` lets you chain together multiple operators on your data that both have a `fit` method.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "s = StandardScaler()\nlr = LinearRegression()",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:33:28.695381Z",
          "start_time": "2019-02-19T17:33:28.691865Z"
        },
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Combine multiple processing steps into a `Pipeline`\n\nA pipeline contains a series of steps, where a step is (\"name of step\", actual_model). The \"name of step\" string is only used to help you identify which step you are on, and to allow you to specify parameters at that step.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "estimator = Pipeline([(\"scaler\", s),\n                      (\"regression\", lr)])",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:33:32.657281Z",
          "start_time": "2019-02-19T17:33:32.653852Z"
        },
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### `cross_val_predict`\n\n[`cross_val_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) is a function that does K-fold cross validation for us, appropriately fitting and transforming at every step of the way.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "kf",
      "metadata": {
        "trusted": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "KFold(n_splits=3, random_state=72018, shuffle=True)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "predictions = cross_val_predict(estimator, X, y, cv=kf)",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:35:55.255356Z",
          "start_time": "2019-02-19T17:35:55.240376Z"
        },
        "trusted": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "r2_score(y, predictions)",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:36:03.801732Z",
          "start_time": "2019-02-19T17:36:03.796646Z"
        },
        "scrolled": true,
        "trusted": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.7063531064161559"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "np.mean(scores) # almost identical!",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:36:19.831481Z",
          "start_time": "2019-02-19T17:36:19.827131Z"
        },
        "trusted": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.7060392060427612"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Note that `cross_val_predict` doesn't use the same model for all steps; the predictions for each row are made when that row is in the validation set. We really have the collected results of 3 (i.e. `kf.num_splits`) different models.\n\nWhen we are done, `estimator` is still not fitted. If we want to predict on *new* data, we still have to train our `estimator`.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Hyperparameter tuning\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Definition\n\n**Hyperparameter tuning** involves using cross validation (or train-test split) to determine which hyperparameters are most likely to generate a model that *generalizes* well outside of your sample.\n\n### Mechanics\n\nWe can generate an exponentially spaces range of values using the numpy [`geomspace`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.geomspace.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01#numpy.geomspace) function.\n\n```python\nnp.geomspace(1, 1000, num=4)\n```\n\nproduces:\n\n```\narray([    1.,    10.,   100.,  1000.])\n```\n\nUse this function to generate a list of length 10 called `alphas` for hyperparameter tuning:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "alphas = np.geomspace(1e-9, 1e0, num=10)\nalphas",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:40:36.220744Z",
          "start_time": "2019-02-19T17:40:36.214714Z"
        },
        "trusted": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02,\n       1.e-01, 1.e+00])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "The code below tunes the `alpha` hyperparameter for Lasso regression.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scores = []\ncoefs = []\nfor alpha in alphas:\n    las = Lasso(alpha=alpha, max_iter=100000)\n    \n    estimator = Pipeline([\n        (\"scaler\", s),\n        (\"lasso_regression\", las)])\n\n    predictions = cross_val_predict(estimator, X, y, cv = kf)\n    \n    score = r2_score(y, predictions)\n    \n    scores.append(score)",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:47:34.947390Z",
          "start_time": "2019-02-19T17:47:34.845011Z"
        },
        "trusted": true
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "list(zip(alphas,scores))",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:47:35.397285Z",
          "start_time": "2019-02-19T17:47:35.390917Z"
        },
        "trusted": true
      },
      "execution_count": 21,
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[(1e-09, 0.7063531064981925),\n (1e-08, 0.7063531072356071),\n (1e-07, 0.7063531145602442),\n (1e-06, 0.7063531882052065),\n (9.999999999999999e-06, 0.7063539165191506),\n (0.0001, 0.706361268093463),\n (0.001, 0.7064334670415461),\n (0.01, 0.7070865958083233),\n (0.1, 0.705838151167185),\n (1.0, 0.6512724532884888)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "Lasso(alpha=1e-6).fit(X, y).coef_",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:48:16.943881Z",
          "start_time": "2019-02-19T17:48:16.937741Z"
        },
        "trusted": true
      },
      "execution_count": 22,
      "outputs": [
        {
          "execution_count": 22,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([-1.07170372e-01,  4.63952623e-02,  2.08588308e-02,  2.68854318e+00,\n       -1.77954207e+01,  3.80475296e+00,  7.50802707e-04, -1.47575348e+00,\n        3.05654279e-01, -1.23293755e-02, -9.53459908e-01,  9.39253013e-03,\n       -5.25467196e-01])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "Lasso(alpha=1.0).fit(X, y).coef_",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:48:40.778026Z",
          "start_time": "2019-02-19T17:48:40.771732Z"
        },
        "trusted": true
      },
      "execution_count": 23,
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([-0.06342255,  0.04916867, -0.        ,  0.        , -0.        ,\n        0.94678567,  0.02092737, -0.66900864,  0.26417501, -0.01520915,\n       -0.72319901,  0.00829117, -0.76143296])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(10,6))\nplt.semilogx(alphas, scores, '-o')\nplt.xlabel('$\\\\alpha$')\nplt.ylabel('$R^2$');",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:46:03.208768Z",
          "start_time": "2019-02-19T17:46:02.898338Z"
        },
        "trusted": true
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Exercise\n\nAdd `PolynomialFeatures` to this `Pipeline`, and re-run the cross validation with the `PolynomialFeatures` added.\n\n**Hint #1:** pipelines process input from first to last. Think about the order that it would make sense to add Polynomial Features to the data in sequence and add them in the appropriate place in the pipeline.\n\n**Hint #2:** you should see a significant increase in cross validation accuracy from doing this\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pf = PolynomialFeatures(degree=3)\n\nscores = []\nalphas = np.geomspace(0.06, 6.0, 20)\nfor alpha in alphas:\n    las = Lasso(alpha=alpha, max_iter=100000)\n    \n    estimator = Pipeline([\n        (\"scaler\", s),\n        (\"make_higher_degree\", pf),\n        (\"lasso_regression\", las)])\n\n    predictions = cross_val_predict(estimator, X, y, cv = kf)\n    \n    score = r2_score(y, predictions)\n    \n    scores.append(score)\n    ",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:56:02.883875Z",
          "start_time": "2019-02-19T17:56:00.477593Z"
        },
        "trusted": true
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "If you store the results in a list called `scores`, the following will work:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.semilogx(alphas, scores);",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:56:05.154628Z",
          "start_time": "2019-02-19T17:56:04.987932Z"
        },
        "trusted": true
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Once we have found the hyperparameter (alpha~1e-2=0.01)\n# make the model and train it on ALL the data\n# Then release it into the wild .....\nbest_estimator = Pipeline([\n                    (\"scaler\", s),\n                    (\"make_higher_degree\", PolynomialFeatures(degree=2)),\n                    (\"lasso_regression\", Lasso(alpha=0.03))])\n\nbest_estimator.fit(X, y)\nbest_estimator.score(X, y)",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:56:40.051147Z",
          "start_time": "2019-02-19T17:56:40.009641Z"
        },
        "trusted": true
      },
      "execution_count": 27,
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.9134777735196521"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "best_estimator.named_steps[\"lasso_regression\"].coef_",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:56:51.526585Z",
          "start_time": "2019-02-19T17:56:51.521094Z"
        },
        "trusted": true
      },
      "execution_count": 28,
      "outputs": [
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([ 0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n        0.00000000e+00, -1.00309168e+00,  3.32679107e+00, -1.01840878e+00,\n       -2.56161421e+00,  1.12778302e+00, -1.72266155e+00, -5.37088506e-01,\n        4.39555878e-01, -3.39542586e+00,  7.22387712e-02,  0.00000000e+00,\n        0.00000000e+00,  3.53653554e+00, -0.00000000e+00,  3.72285440e-01,\n        0.00000000e+00,  0.00000000e+00, -5.49528703e-01, -0.00000000e+00,\n       -0.00000000e+00, -4.05522485e-02,  2.25864611e-01,  1.78508858e-01,\n        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  6.50874606e-02,\n       -0.00000000e+00, -2.07295802e-01, -0.00000000e+00,  3.71781995e-01,\n        0.00000000e+00, -0.00000000e+00, -5.89531100e-02,  3.47180625e-01,\n        0.00000000e+00,  9.23666274e-01,  3.48873365e-01,  7.29463442e-02,\n        0.00000000e+00,  0.00000000e+00,  7.68485586e-02, -7.21083596e-01,\n        0.00000000e+00, -5.98542558e-01,  4.18420677e-01, -7.98165728e-01,\n       -7.25062683e-01,  2.34818861e-01, -0.00000000e+00, -0.00000000e+00,\n        0.00000000e+00, -1.68164447e-02,  0.00000000e+00, -4.04477826e-01,\n       -4.22989874e-01, -4.06983988e-01, -3.75443720e-01,  4.17684564e-01,\n       -8.91841193e-01,  0.00000000e+00, -2.69309481e-01,  0.00000000e+00,\n        1.02286785e-01,  2.02570379e-01, -6.88345376e-01, -0.00000000e+00,\n       -1.08598703e+00, -3.98751731e-01, -9.37684760e-01, -1.17343147e-01,\n       -7.37427594e-01,  0.00000000e+00,  0.00000000e+00,  1.36340670e+00,\n       -0.00000000e+00, -2.94691228e-03, -8.98125013e-01, -8.68198373e-01,\n        8.03396788e-01, -1.91683803e-01, -1.14706070e-01,  0.00000000e+00,\n       -0.00000000e+00,  5.83161589e-01, -0.00000000e+00,  5.81365491e-02,\n        0.00000000e+00, -2.32896159e-01, -1.12440837e+00,  0.00000000e+00,\n        1.96286997e+00, -0.00000000e+00, -1.00915801e+00, -7.04656486e-02,\n       -1.06456357e-02, -4.78389591e-02, -3.97645601e-01, -3.84121840e-01,\n        9.97402419e-01])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Exercise\n\nDo the same, but with `Ridge` regression\n\nWhich model, `Ridge` or `Lasso`, performs best with its optimal hyperparameters on the Boston dataset?\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pf = PolynomialFeatures(degree=2)\nalphas = np.geomspace(4, 20, 20)\nscores=[]\nfor alpha in alphas:\n    ridge = Ridge(alpha=alpha, max_iter=100000)\n\n    estimator = Pipeline([\n        (\"scaler\", s),\n        (\"polynomial_features\", pf),\n        (\"ridge_regression\", ridge)])\n\n    predictions = cross_val_predict(estimator, X, y, cv = kf)\n    score = r2_score(y, predictions)\n    scores.append(score)\n\nplt.plot(alphas, scores)",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:59:17.634414Z",
          "start_time": "2019-02-19T17:59:17.238684Z"
        },
        "trusted": true
      },
      "execution_count": 29,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[<matplotlib.lines.Line2D at 0x57561a0>]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "**Conclusion:** Both Lasso and Ridge with proper hyperparameter tuning give better results than plain ol' Linear Regression!\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Exercise:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now, for whatever your best overall hyperparameter was:\n\n*   Standardize the data\n*   Fit and predict on the entire dataset\n*   See what the largest coefficients were\n\n    *   Hint: use\n\n    ```python\n    dict(zip(model.coef_, pf.get_feature_names()))\n    ```\n\n    for your model `model` to get the feature names from `PolynomialFeatures`.\n\n    Then, use\n\n    ```python\n    dict(zip(list(range(len(X.columns.values))), X.columns.values))\n    ```\n\n    to see which features in the `PolynomialFeatures` DataFrame correspond to which columns in the original DataFrame.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Once we have found the hyperparameter (alpha~1e-2=0.01)\n# make the model and train it on ALL the data\n# Then release it into the wild .....\nbest_estimator = Pipeline([\n                    (\"scaler\", s),\n                    (\"make_higher_degree\", PolynomialFeatures(degree=2)),\n                    (\"lasso_regression\", Lasso(alpha=0.03))])\n\nbest_estimator.fit(X, y)\nbest_estimator.score(X, y)",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:56:40.051147Z",
          "start_time": "2019-02-19T17:56:40.009641Z"
        },
        "trusted": true
      },
      "execution_count": 30,
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.9134777735196521"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "df_importances = pd.DataFrame(zip(best_estimator.named_steps[\"make_higher_degree\"].get_feature_names(),\n                 best_estimator.named_steps[\"lasso_regression\"].coef_,\n))",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T17:56:51.526585Z",
          "start_time": "2019-02-19T17:56:51.521094Z"
        },
        "trusted": true
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "col_names_dict = dict(zip(list(range(len(X.columns.values))), X.columns.values))",
      "metadata": {
        "trusted": true
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "col_names_dict",
      "metadata": {
        "trusted": true
      },
      "execution_count": 33,
      "outputs": [
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{0: 'CRIM',\n 1: 'ZN',\n 2: 'INDUS',\n 3: 'CHAS',\n 4: 'NOX',\n 5: 'RM',\n 6: 'AGE',\n 7: 'DIS',\n 8: 'RAD',\n 9: 'TAX',\n 10: 'PTRATIO',\n 11: 'B',\n 12: 'LSTAT'}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "df_importances.sort_values(by=1)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 34,
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         0         1\n13     x12 -3.395426\n8       x7 -2.561614\n10      x9 -1.722662\n94  x8 x12 -1.124408\n72   x5 x8 -1.085987\n..     ...       ...\n9       x8  1.127783\n79   x6 x8  1.363407\n96  x9 x10  1.962870\n6       x5  3.326791\n17   x0 x3  3.536536\n\n[105 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13</th>\n      <td>x12</td>\n      <td>-3.395426</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>x7</td>\n      <td>-2.561614</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>x9</td>\n      <td>-1.722662</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>x8 x12</td>\n      <td>-1.124408</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>x5 x8</td>\n      <td>-1.085987</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>x8</td>\n      <td>1.127783</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>x6 x8</td>\n      <td>1.363407</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>x9 x10</td>\n      <td>1.962870</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>x5</td>\n      <td>3.326791</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>x0 x3</td>\n      <td>3.536536</td>\n    </tr>\n  </tbody>\n</table>\n<p>105 rows Ã— 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Grid Search CV\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "To do cross-validation, we used two techniques:\n\n*   use `KFolds` and manually create a loop to do cross-validation\n*   use `cross_val_predict` and `score` to get a cross-valiated score in a couple of lines.\n\nTo do hyper-parameter tuning, we see a general pattern:\n\n*   use `cross_val_predict` and `score` in a manually written loop over hyperparemeters, then select the best one.\n\nPerhaps not surprisingly, there is a function that does this for us -- `GridSearchCV`\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import GridSearchCV\n\n# Same estimator as before\nestimator = Pipeline([(\"scaler\", StandardScaler()),\n        (\"polynomial_features\", PolynomialFeatures()),\n        (\"ridge_regression\", Ridge())])\n\nparams = {\n    'polynomial_features__degree': [1, 2, 3],\n    'ridge_regression__alpha': np.geomspace(4, 20, 30)\n}\n\ngrid = GridSearchCV(estimator, params, cv=kf)",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T18:02:31.945804Z",
          "start_time": "2019-02-19T18:02:31.938416Z"
        },
        "trusted": true
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "grid.fit(X, y)",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T18:02:49.319148Z",
          "start_time": "2019-02-19T18:02:46.093880Z"
        },
        "trusted": true
      },
      "execution_count": 36,
      "outputs": [
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "GridSearchCV(cv=KFold(n_splits=3, random_state=72018, shuffle=True),\n             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n                                       ('polynomial_features',\n                                        PolynomialFeatures()),\n                                       ('ridge_regression', Ridge())]),\n             param_grid={'polynomial_features__degree': [1, 2, 3],\n                         'ridge_regression__alpha': array([ 4.        ,  4.22826702,  4.46956049,  4.7246238 ,  4.99424274,\n        5.27924796,  5.58051751,  5.89897953,  6.23561514,  6.59146146,\n        6.96761476,  7.36523392,  7.78554391,  8.22983963,  8.69948987,\n        9.19594151,  9.72072404, 10.27545421, 10.86184103, 11.48169104,\n       12.13691388, 12.82952815, 13.56166768, 14.33558803, 15.15367351,\n       16.01844446, 16.93256509, 17.89885162, 18.92028098, 20.        ])})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "grid.best_score_, grid.best_params_",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T18:03:07.016198Z",
          "start_time": "2019-02-19T18:03:07.010215Z"
        },
        "trusted": true
      },
      "execution_count": 37,
      "outputs": [
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(0.8504982950750936,\n {'polynomial_features__degree': 2,\n  'ridge_regression__alpha': 15.153673507519274})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "y_predict = grid.predict(X)",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T18:03:31.735568Z",
          "start_time": "2019-02-19T18:03:31.728658Z"
        },
        "trusted": true
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# This includes both in-sample and out-of-sample\nr2_score(y, y_predict)",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T18:04:17.838943Z",
          "start_time": "2019-02-19T18:04:17.832872Z"
        },
        "trusted": true
      },
      "execution_count": 39,
      "outputs": [
        {
          "execution_count": 39,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.9149145594213683"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# Notice that \"grid\" is a fit object!\n# We can use grid.predict(X_test) to get brand new predictions!\ngrid.best_estimator_.named_steps['ridge_regression'].coef_",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T18:04:27.088854Z",
          "start_time": "2019-02-19T18:04:27.082915Z"
        },
        "trusted": true
      },
      "execution_count": 40,
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([ 0.00000000e+00, -1.27346408e-01, -6.16205046e-03,  2.36135244e-02,\n        1.00398027e-01, -9.74110586e-01,  3.26236441e+00, -9.65057238e-01,\n       -1.96344725e+00,  8.56769182e-01, -1.01488960e+00, -7.06985966e-01,\n        5.52029222e-01, -3.03254502e+00,  7.74127927e-02,  7.24276605e-02,\n        6.82776638e-02,  1.72849044e+00, -4.80758341e-01,  5.76219972e-01,\n        1.28132069e-01,  2.22931335e-01, -7.45243542e-01,  1.66582495e-01,\n       -8.00025634e-02, -8.54571642e-02,  5.07490801e-01,  2.14820391e-01,\n       -1.48833274e-01,  1.42098626e-01,  1.93770221e-01,  5.02304885e-02,\n       -1.12667821e-01, -2.77559685e-01, -1.32870713e-01,  7.32239658e-01,\n        5.26857333e-02,  8.89966580e-02, -2.72228558e-01,  5.84383917e-01,\n        1.06306947e-01,  9.62971619e-01,  5.76845132e-01,  5.33378179e-01,\n        7.07913980e-01, -6.21760626e-02,  7.57641545e-02, -4.28157866e-01,\n        2.40651011e-01, -6.82201736e-01,  3.40931549e-01, -9.62217889e-01,\n       -8.14997204e-01,  2.81353294e-01,  5.50023518e-02,  8.65917517e-02,\n        6.28285056e-01, -1.40764851e-01, -1.03645734e-01, -3.81965497e-01,\n       -4.48817407e-01, -4.46562934e-01, -4.97293983e-01,  7.52862844e-01,\n       -8.00745322e-01,  7.86779267e-02, -5.78298566e-01, -4.98398516e-02,\n        5.37001246e-01,  2.24913740e-01, -7.11059542e-01,  5.70498060e-02,\n       -7.85214394e-01, -9.18516132e-01, -1.02907666e+00, -1.58937491e-01,\n       -7.77699453e-01,  1.42895792e-01,  7.72299871e-02,  1.08239035e+00,\n        3.98859145e-02, -7.26596891e-02, -9.64695031e-01, -1.12682105e+00,\n        1.01829108e+00, -6.12786851e-01, -4.22714073e-01, -1.41672983e-01,\n       -2.68672373e-01,  8.23071041e-01, -8.66106901e-01,  8.83695240e-01,\n        3.63975663e-01, -1.13200717e-01, -1.12043738e+00,  2.19170412e-03,\n        1.30087563e+00, -3.65505003e-01, -1.08425883e+00, -1.16852284e-01,\n        8.62081670e-02,  1.40937541e-03, -3.62535906e-01, -4.04519520e-01,\n        8.07960994e-01])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "grid.cv_results_",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-19T18:05:34.756588Z",
          "start_time": "2019-02-19T18:05:34.728508Z"
        },
        "trusted": true
      },
      "execution_count": 41,
      "outputs": [
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'mean_fit_time': array([0.00633335, 0.00733336, 0.00733344, 0.00666674, 0.00699989,\n        0.00700005, 0.00566673, 0.00600004, 0.00599996, 0.00533342,\n        0.00533342, 0.00566673, 0.00733328, 0.00633327, 0.00633327,\n        0.00733336, 0.00633319, 0.00633327, 0.00666674, 0.00633335,\n        0.00700005, 0.00533326, 0.00566673, 0.00566665, 0.00599988,\n        0.00500003, 0.00566657, 0.00599996, 0.00599988, 0.00633351,\n        0.00999999, 0.0116667 , 0.01066661, 0.00999999, 0.011     ,\n        0.01099992, 0.01000007, 0.01066661, 0.0103333 , 0.01033346,\n        0.01033322, 0.00999991, 0.01000007, 0.00999999, 0.01066653,\n        0.00999999, 0.01166654, 0.01000007, 0.00999991, 0.0103333 ,\n        0.01100016, 0.00999991, 0.00999999, 0.01033338, 0.01000007,\n        0.01066653, 0.01000015, 0.01066653, 0.00999999, 0.00966668,\n        0.08699989, 0.08799982, 0.08933338, 0.08666666, 0.08933338,\n        0.08833345, 0.08733336, 0.09133355, 0.08699989, 0.08633327,\n        0.08966668, 0.0933334 , 0.10300001, 0.09600012, 0.09466672,\n        0.09966667, 0.09066669, 0.10099999, 0.09733351, 0.0916667 ,\n        0.09000007, 0.09366679, 0.08900007, 0.08799982, 0.08733304,\n        0.09133323, 0.09666673, 0.09233324, 0.10666649, 0.09900006]),\n 'std_fit_time': array([9.42909300e-04, 1.24717123e-03, 9.42684517e-04, 1.69965908e-03,\n        8.16534738e-04, 8.16340070e-04, 4.71370354e-04, 1.94667955e-07,\n        1.12391596e-07, 4.71538951e-04, 4.71538951e-04, 4.71538951e-04,\n        1.24712873e-03, 9.42515924e-04, 1.24734113e-03, 1.24742609e-03,\n        1.88559381e-03, 1.24721369e-03, 4.71257962e-04, 4.71538951e-04,\n        8.16437410e-04, 4.71314168e-04, 4.71538951e-04, 4.71482786e-04,\n        1.12391596e-07, 1.12391596e-07, 4.71426560e-04, 8.16534738e-04,\n        8.16437410e-04, 4.71426560e-04, 1.94667955e-07, 1.69976818e-03,\n        4.71370394e-04, 1.94667955e-07, 2.24783192e-07, 8.16632070e-04,\n        1.12391596e-07, 4.71538951e-04, 4.71370354e-04, 4.71426560e-04,\n        4.71426560e-04, 1.12391596e-07, 1.12391596e-07, 1.94667955e-07,\n        9.42796908e-04, 8.16534753e-04, 1.69973701e-03, 1.12391596e-07,\n        1.12391596e-07, 4.71538951e-04, 8.16437402e-04, 2.24783192e-07,\n        1.94667955e-07, 4.71482786e-04, 2.24783192e-07, 9.42796908e-04,\n        8.16340070e-04, 9.42965491e-04, 1.94667955e-07, 4.71370354e-04,\n        8.16437402e-04, 1.41411106e-03, 1.24723493e-03, 4.71426560e-04,\n        2.05475888e-03, 3.39939609e-03, 2.62470110e-03, 4.98891849e-03,\n        1.41427965e-03, 1.24712873e-03, 3.68161369e-03, 7.13372198e-03,\n        4.89901375e-03, 6.37714076e-03, 5.43648819e-03, 5.55777966e-03,\n        9.42796908e-04, 1.41422345e-03, 4.49688113e-03, 2.35702036e-03,\n        1.12391596e-07, 4.98889725e-03, 1.12391596e-07, 8.16437402e-04,\n        4.71482745e-04, 5.43655641e-03, 3.39944286e-03, 2.62470110e-03,\n        2.49446986e-03, 2.94400387e-03]),\n 'mean_score_time': array([0.00333333, 0.00266663, 0.00266671, 0.00333325, 0.0030001 ,\n        0.00333333, 0.00366664, 0.00233324, 0.00200009, 0.00199986,\n        0.00200001, 0.00299994, 0.00266663, 0.00333325, 0.0030001 ,\n        0.00266663, 0.00333341, 0.00300002, 0.00266671, 0.00266663,\n        0.00266671, 0.00300002, 0.00266663, 0.00199993, 0.00233348,\n        0.00233324, 0.00266679, 0.0023334 , 0.00266671, 0.00299994,\n        0.00266663, 0.00266671, 0.00266663, 0.00333341, 0.00266655,\n        0.0023334 , 0.00266663, 0.0030001 , 0.00233324, 0.00266671,\n        0.00266655, 0.00266671, 0.00299994, 0.00266671, 0.00266679,\n        0.00333341, 0.0030001 , 0.00266663, 0.0023334 , 0.00266663,\n        0.00266663, 0.00233332, 0.00266671, 0.00300002, 0.00199993,\n        0.00266671, 0.00266663, 0.00300002, 0.00266671, 0.00300002,\n        0.00366656, 0.00366672, 0.00433342, 0.00366672, 0.00333341,\n        0.00333325, 0.00366664, 0.00433326, 0.00400011, 0.00300002,\n        0.00366672, 0.00466657, 0.00466665, 0.00333325, 0.00366664,\n        0.00400011, 0.00333325, 0.00333333, 0.00433318, 0.00366672,\n        0.00399995, 0.00333317, 0.00300002, 0.0030001 , 0.00400011,\n        0.00333333, 0.00500003, 0.00333333, 0.00366672, 0.00399995]),\n 'std_score_time': array([4.71538951e-04, 9.42796908e-04, 9.42740707e-04, 1.24721369e-03,\n        1.41439204e-03, 1.24731989e-03, 4.71538951e-04, 4.71482745e-04,\n        0.00000000e+00, 0.00000000e+00, 1.12391596e-07, 1.41416726e-03,\n        9.42796908e-04, 4.71426560e-04, 1.12391596e-07, 4.71482745e-04,\n        1.24704377e-03, 8.16437402e-04, 9.42740728e-04, 9.42796908e-04,\n        9.43077882e-04, 0.00000000e+00, 4.71482745e-04, 1.12391596e-07,\n        4.71482745e-04, 4.71482745e-04, 4.71426560e-04, 4.71538951e-04,\n        4.71201776e-04, 8.16534738e-04, 4.71314168e-04, 4.71370354e-04,\n        4.71482786e-04, 4.71314168e-04, 4.71257962e-04, 4.71538951e-04,\n        4.71482745e-04, 1.12391596e-07, 4.71314168e-04, 4.71370354e-04,\n        9.42853099e-04, 4.71370354e-04, 1.12391596e-07, 4.71370394e-04,\n        4.71426560e-04, 1.24742609e-03, 1.12391596e-07, 4.71314168e-04,\n        4.71538951e-04, 4.71482786e-04, 4.71482745e-04, 4.71595137e-04,\n        4.71538951e-04, 1.94667955e-07, 1.12391596e-07, 4.71201776e-04,\n        9.42796908e-04, 0.00000000e+00, 4.71370394e-04, 1.94667955e-07,\n        4.71482786e-04, 4.71426560e-04, 4.71595137e-04, 4.71426560e-04,\n        4.71482745e-04, 4.71426560e-04, 4.71370354e-04, 1.24712873e-03,\n        2.24783192e-07, 1.94667955e-07, 4.71257962e-04, 1.69969026e-03,\n        9.43021692e-04, 4.71257962e-04, 4.71370354e-04, 1.41433586e-03,\n        4.71595137e-04, 4.71538951e-04, 4.71426560e-04, 4.71426560e-04,\n        0.00000000e+00, 4.71314168e-04, 0.00000000e+00, 2.24783192e-07,\n        8.16437410e-04, 4.71707529e-04, 8.16632101e-04, 4.71538951e-04,\n        4.71426560e-04, 0.00000000e+00]),\n 'param_polynomial_features__degree': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n                    2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n              mask=[False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False],\n        fill_value='?',\n             dtype=object),\n 'param_ridge_regression__alpha': masked_array(data=[4.0, 4.228267015769416, 4.4695604891609,\n                    4.724623797826311, 4.994242741567055,\n                    5.279247963228449, 5.58051750774668, 5.898979527232257,\n                    6.235615140423803, 6.591461455321584,\n                    6.9676147643129305, 7.365233921633089,\n                    7.785543913566802, 8.229839632389709,\n                    8.699489865676323, 9.195941513264877,\n                    9.720724044870641, 10.275454212080797,\n                    10.861841029247536, 11.481691038624568,\n                    12.136913875967887, 12.82952815374728,\n                    13.561667680093684, 14.335588032641558,\n                    15.153673507519274, 16.018444464895637,\n                    16.932565093713098, 17.898851619528912,\n                    18.920280980751272, 20.0, 4.0, 4.228267015769416,\n                    4.4695604891609, 4.724623797826311, 4.994242741567055,\n                    5.279247963228449, 5.58051750774668, 5.898979527232257,\n                    6.235615140423803, 6.591461455321584,\n                    6.9676147643129305, 7.365233921633089,\n                    7.785543913566802, 8.229839632389709,\n                    8.699489865676323, 9.195941513264877,\n                    9.720724044870641, 10.275454212080797,\n                    10.861841029247536, 11.481691038624568,\n                    12.136913875967887, 12.82952815374728,\n                    13.561667680093684, 14.335588032641558,\n                    15.153673507519274, 16.018444464895637,\n                    16.932565093713098, 17.898851619528912,\n                    18.920280980751272, 20.0, 4.0, 4.228267015769416,\n                    4.4695604891609, 4.724623797826311, 4.994242741567055,\n                    5.279247963228449, 5.58051750774668, 5.898979527232257,\n                    6.235615140423803, 6.591461455321584,\n                    6.9676147643129305, 7.365233921633089,\n                    7.785543913566802, 8.229839632389709,\n                    8.699489865676323, 9.195941513264877,\n                    9.720724044870641, 10.275454212080797,\n                    10.861841029247536, 11.481691038624568,\n                    12.136913875967887, 12.82952815374728,\n                    13.561667680093684, 14.335588032641558,\n                    15.153673507519274, 16.018444464895637,\n                    16.932565093713098, 17.898851619528912,\n                    18.920280980751272, 20.0],\n              mask=[False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False, False, False, False, False, False, False,\n                    False, False],\n        fill_value='?',\n             dtype=object),\n 'params': [{'polynomial_features__degree': 1, 'ridge_regression__alpha': 4.0},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 4.228267015769416},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 4.4695604891609},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 4.724623797826311},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 4.994242741567055},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 5.279247963228449},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 5.58051750774668},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 5.898979527232257},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 6.235615140423803},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 6.591461455321584},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 6.9676147643129305},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 7.365233921633089},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 7.785543913566802},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 8.229839632389709},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 8.699489865676323},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 9.195941513264877},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 9.720724044870641},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 10.275454212080797},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 10.861841029247536},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 11.481691038624568},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 12.136913875967887},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 12.82952815374728},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 13.561667680093684},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 14.335588032641558},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 15.153673507519274},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 16.018444464895637},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 16.932565093713098},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 17.898851619528912},\n  {'polynomial_features__degree': 1,\n   'ridge_regression__alpha': 18.920280980751272},\n  {'polynomial_features__degree': 1, 'ridge_regression__alpha': 20.0},\n  {'polynomial_features__degree': 2, 'ridge_regression__alpha': 4.0},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 4.228267015769416},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 4.4695604891609},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 4.724623797826311},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 4.994242741567055},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 5.279247963228449},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 5.58051750774668},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 5.898979527232257},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 6.235615140423803},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 6.591461455321584},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 6.9676147643129305},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 7.365233921633089},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 7.785543913566802},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 8.229839632389709},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 8.699489865676323},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 9.195941513264877},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 9.720724044870641},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 10.275454212080797},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 10.861841029247536},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 11.481691038624568},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 12.136913875967887},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 12.82952815374728},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 13.561667680093684},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 14.335588032641558},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 15.153673507519274},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 16.018444464895637},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 16.932565093713098},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 17.898851619528912},\n  {'polynomial_features__degree': 2,\n   'ridge_regression__alpha': 18.920280980751272},\n  {'polynomial_features__degree': 2, 'ridge_regression__alpha': 20.0},\n  {'polynomial_features__degree': 3, 'ridge_regression__alpha': 4.0},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 4.228267015769416},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 4.4695604891609},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 4.724623797826311},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 4.994242741567055},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 5.279247963228449},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 5.58051750774668},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 5.898979527232257},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 6.235615140423803},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 6.591461455321584},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 6.9676147643129305},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 7.365233921633089},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 7.785543913566802},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 8.229839632389709},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 8.699489865676323},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 9.195941513264877},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 9.720724044870641},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 10.275454212080797},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 10.861841029247536},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 11.481691038624568},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 12.136913875967887},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 12.82952815374728},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 13.561667680093684},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 14.335588032641558},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 15.153673507519274},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 16.018444464895637},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 16.932565093713098},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 17.898851619528912},\n  {'polynomial_features__degree': 3,\n   'ridge_regression__alpha': 18.920280980751272},\n  {'polynomial_features__degree': 3, 'ridge_regression__alpha': 20.0}],\n 'split0_test_score': array([0.67211108, 0.67210314, 0.67209324, 0.67208118, 0.67206672,\n        0.67204963, 0.67202966, 0.67200655, 0.67198001, 0.67194974,\n        0.67191544, 0.67187678, 0.67183341, 0.67178499, 0.67173113,\n        0.67167146, 0.67160557, 0.67153305, 0.67145348, 0.6713664 ,\n        0.67127137, 0.6711679 , 0.67105552, 0.6709337 , 0.67080194,\n        0.67065969, 0.67050638, 0.67034142, 0.67016421, 0.66997409,\n        0.84255141, 0.842198  , 0.84184328, 0.84148681, 0.84112806,\n        0.8407665 , 0.8404015 , 0.84003242, 0.83965857, 0.83927923,\n        0.83889363, 0.83850099, 0.83810051, 0.83769135, 0.83727266,\n        0.83684358, 0.83640324, 0.83595074, 0.83548519, 0.83500569,\n        0.83451133, 0.83400119, 0.83347436, 0.83292992, 0.83236695,\n        0.83178453, 0.83118176, 0.8305577 , 0.82991147, 0.82924215,\n        0.46032273, 0.46657733, 0.47271332, 0.47874141, 0.48467138,\n        0.49051215, 0.49627176, 0.50195736, 0.50757525, 0.51313086,\n        0.51862881, 0.52407294, 0.52946628, 0.53481114, 0.54010914,\n        0.54536121, 0.55056769, 0.55572834, 0.5608424 , 0.56590865,\n        0.57092545, 0.57589079, 0.58080236, 0.58565758, 0.59045368,\n        0.5951877 , 0.59985659, 0.60445722, 0.60898644, 0.61344108]),\n 'split1_test_score': array([0.74823479, 0.74820653, 0.74817547, 0.74814136, 0.74810392,\n        0.74806286, 0.74801786, 0.74796859, 0.7479147 , 0.74785579,\n        0.74779145, 0.74772124, 0.74764471, 0.74756134, 0.74747062,\n        0.74737198, 0.74726483, 0.74714854, 0.74702245, 0.74688586,\n        0.74673803, 0.74657817, 0.74640546, 0.74621904, 0.74601799,\n        0.74580135, 0.74556811, 0.74531721, 0.74504752, 0.74475787,\n        0.86557853, 0.86603127, 0.86645483, 0.86684876, 0.86721267,\n        0.86754631, 0.86784949, 0.86812211, 0.86836416, 0.8685757 ,\n        0.86875685, 0.86890779, 0.86902875, 0.86912   , 0.86918184,\n        0.86921458, 0.86921854, 0.86919404, 0.86914139, 0.86906086,\n        0.8689527 , 0.86881708, 0.86865414, 0.86846395, 0.86824647,\n        0.8680016 , 0.86772912, 0.86742872, 0.86709996, 0.8667423 ,\n        0.62240449, 0.63405949, 0.64527978, 0.65607193, 0.66644299,\n        0.67640045, 0.68595224, 0.69510667, 0.70387245, 0.71225862,\n        0.72027452, 0.72792977, 0.73523423, 0.74219795, 0.74883117,\n        0.75514421, 0.76114752, 0.76685157, 0.77226688, 0.77740393,\n        0.78227315, 0.78688487, 0.79124935, 0.79537665, 0.79927671,\n        0.80295923, 0.80643374, 0.80970949, 0.81279549, 0.81570048]),\n 'split2_test_score': array([0.70180089, 0.70198642, 0.70217792, 0.70237536, 0.70257867,\n        0.70278778, 0.70300256, 0.70322288, 0.70344855, 0.70367937,\n        0.70391508, 0.70415539, 0.70439999, 0.70464849, 0.70490048,\n        0.70515549, 0.70541302, 0.7056725 , 0.7059333 , 0.70619477,\n        0.70645615, 0.70671666, 0.70697543, 0.70723154, 0.707484  ,\n        0.70773173, 0.70797357, 0.70820831, 0.70843462, 0.7086511 ,\n        0.82439713, 0.82556196, 0.82674219, 0.82793488, 0.82913699,\n        0.83034544, 0.83155716, 0.83276905, 0.83397809, 0.83518129,\n        0.83637577, 0.83755872, 0.8387275 , 0.83987956, 0.84101252,\n        0.84212417, 0.84321244, 0.84427542, 0.8453114 , 0.84631879,\n        0.84729616, 0.84824222, 0.84915581, 0.85003589, 0.85088147,\n        0.85169166, 0.85246561, 0.85320251, 0.85390151, 0.85456176,\n        0.19693116, 0.21816001, 0.23890851, 0.25917159, 0.27894594,\n        0.29822995, 0.3170236 , 0.33532837, 0.35314709, 0.37048386,\n        0.38734392, 0.4037335 , 0.41965974, 0.43513055, 0.45015451,\n        0.46474072, 0.47889874, 0.49263844, 0.50596996, 0.51890355,\n        0.53144957, 0.54361833, 0.55542009, 0.56686496, 0.57796288,\n        0.58872354, 0.59915638, 0.60927057, 0.61907495, 0.62857805]),\n 'mean_test_score': array([0.70738225, 0.70743203, 0.70748221, 0.70753263, 0.7075831 ,\n        0.70763342, 0.70768336, 0.70773267, 0.70778109, 0.7078283 ,\n        0.70787399, 0.7079178 , 0.70795937, 0.70799827, 0.70803407,\n        0.70806631, 0.70809447, 0.70811803, 0.70813641, 0.70814901,\n        0.70815518, 0.70815424, 0.70814547, 0.7081281 , 0.70810131,\n        0.70806425, 0.70801602, 0.70795565, 0.70788212, 0.70779435,\n        0.84417569, 0.84459708, 0.84501344, 0.84542348, 0.84582591,\n        0.84621942, 0.84660271, 0.84697453, 0.84733361, 0.84767874,\n        0.84800875, 0.8483225 , 0.84861892, 0.84889697, 0.84915567,\n        0.84939411, 0.8496114 , 0.84980674, 0.84997933, 0.85012845,\n        0.85025339, 0.8503535 , 0.85042811, 0.85047658, 0.8504983 ,\n        0.8504926 , 0.85045883, 0.85039631, 0.85030431, 0.85018207,\n        0.42655279, 0.43959894, 0.45230054, 0.46466164, 0.47668677,\n        0.48838085, 0.4997492 , 0.51079747, 0.52153159, 0.53195778,\n        0.54208242, 0.55191207, 0.56145342, 0.57071322, 0.57969827,\n        0.58841538, 0.59687131, 0.60507278, 0.61302641, 0.62073871,\n        0.62821605, 0.63546466, 0.6424906 , 0.64929973, 0.65589775,\n        0.66229016, 0.66848224, 0.6744791 , 0.68028563, 0.68590654]),\n 'std_test_score': array([0.03132697, 0.03130679, 0.03128608, 0.03126485, 0.0312431 ,\n        0.03122086, 0.03119812, 0.0311749 , 0.03115122, 0.03112707,\n        0.03110249, 0.03107746, 0.031052  , 0.03102612, 0.03099981,\n        0.03097307, 0.0309459 , 0.03091829, 0.03089021, 0.03086164,\n        0.03083255, 0.03080289, 0.03077261, 0.03074165, 0.03070993,\n        0.03067736, 0.03064384, 0.03060926, 0.03057348, 0.03053636,\n        0.01685142, 0.01660839, 0.01636685, 0.01612856, 0.01589532,\n        0.01566901, 0.01545153, 0.01524477, 0.01505058, 0.01487079,\n        0.01470709, 0.01456108, 0.0144342 , 0.01432772, 0.01424271,\n        0.01418002, 0.01414027, 0.01412388, 0.01413098, 0.01416154,\n        0.01421527, 0.01429171, 0.01439024, 0.01451005, 0.01465026,\n        0.01480984, 0.01498772, 0.01518275, 0.01539374, 0.01561947,\n        0.17533244, 0.17085856, 0.1665271 , 0.16233946, 0.15829573,\n        0.15439482, 0.15063455, 0.14701183, 0.14352271, 0.14016261,\n        0.13692638, 0.13380849, 0.13080315, 0.12790443, 0.12510638,\n        0.12240314, 0.11978902, 0.11725859, 0.11480677, 0.11242883,\n        0.11012047, 0.10787782, 0.10569749, 0.10357651, 0.10151239,\n        0.09950306, 0.09754686, 0.09564252, 0.0937891 , 0.09198599]),\n 'rank_test_score': array([60, 59, 58, 57, 56, 55, 54, 53, 52, 50, 49, 47, 45, 44, 42, 40, 39,\n        37, 35, 33, 31, 32, 34, 36, 38, 41, 43, 46, 48, 51, 30, 29, 28, 27,\n        26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11,  9,\n         7,  5,  3,  1,  2,  4,  6,  8, 10, 90, 89, 88, 87, 86, 85, 84, 83,\n        82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66,\n        65, 64, 63, 62, 61], dtype=int32)}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Summary\n\n1.  We can manually generate folds by using `KFolds`\n2.  We can get a score using `cross_val_predict(X, y, cv=KFoldObject_or_integer)`.\n    This will produce the out-of-bag prediction for each row.\n3.  When doing hyperparameter selection, we should be optimizing on out-of-bag scores. This means either using `cross_val_predict` in a loop, or ....\n4.  .... use `GridSearchCV`. GridSearchCV takes a model (or pipeline) and a dictionary of parameters to scan over. It finds the hyperparameter set that has the best out-of-sample score on all the parameters, and calls that it's \"best estimator\". It then retrains on all data with the \"best\" hyper-parameters.\n\n### Extensions\n\nHere are some additional items to keep in mind:\n\n*   There is a `RandomSearchCV` that tries random combination of model parameters. This can be helpful if you have a prohibitive number of combinations to test them all exhaustively.\n*   KFolds will randomly select rows to be in the training and test folds. There are other methods (such as `StratifiedKFolds` and `GroupKFold`, which are useful when you need more control over how the data is split (e.g. to prevent data leakage). You can create these specialized objects and pass them to the `cv` argument of `GridSearchCV`.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "***\n\n### Machine Learning Foundation (C) 2020 IBM Corporation\n",
      "metadata": {}
    }
  ]
}